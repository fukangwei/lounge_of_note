---
title: HOG特征
date: 2019-10-04 12:42:54
categories: opencv和图像处理
mathjax: true
---
&emsp;&emsp;方向梯度直方图(`Histogram of Oriented Gradient`，`HOG`)特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。`Hog`特征结合`SVM`分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。需要提醒的是，`HOG + SVM`进行行人检测的方法是法国研究人员`Dalal`在`2005`的`CVPR`上提出的，而如今虽然有很多行人检测算法不断提出，但基本都是以`HOG + SVM`的思路为主。<!--more-->

### 主要思想

&emsp;&emsp;在一幅图像中，局部目标的表象和形状(`appearance and shape`)能够被梯度或边缘的方向密度分布很好地描述(本质上是因为梯度主要存在于边缘的地方)：

<img src="./HOG特征/new_1.png">

### 具体的实现方法

&emsp;&emsp;首先将图像分成小的连通区域(我们把它叫做`细胞单元`)，然后采集细胞单元中各像素点的梯度的或边缘的方向直方图，最后把这些直方图组合起来就可以构成特征描述器。

### 提高性能

&emsp;&emsp;把这些局部直方图在图像的更大的范围内(我们把它叫`区间`或`block`)进行对比度归一化(`contrast-normalized`)，所采用的方法是：先计算各直方图在这个区间(`block`)中的密度，然后根据这个密度对区间中的各个细胞单元做归一化。通过这个归一化后，能对光照变化和阴影获得更好的效果。

### 优点

&emsp;&emsp;与其他的特征描述方法相比，`HOG`有很多优点。首先，由于`HOG`是在图像的局部方格单元上操作，所以它对图像几何的和光学的形变都能保持很好的不变性，这两种形变只会出现在更大的空间领域上。其次，在粗的空域抽样、精细的方向抽样以及较强的局部光学归一化等条件下，只要行人大体上能够保持直立的姿势，可以容许行人有一些细微的肢体动作，这些细微的动作可以被忽略而不影响检测效果。因此`HOG`特征是特别适合于做图像中的人体检测的。

### HOG特征提取算法

&emsp;&emsp;`HOG`特征提取方法就是将一个`image`：

1. 灰度化(将图像看做一个`(x, y, z(灰度))`的三维图像)。
2. 采用`Gamma`校正法对输入图像进行颜色空间的标准化(归一化)，目的是调节图像的对比度，降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰。
3. 计算图像每个像素的梯度(包括大小和方向)，主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。
4. 将图像划分成小`cells`(例如`6*6像素/cell`)。
5. 统计每个`cell`的梯度直方图(不同梯度的个数)，即可形成每个`cell`的`descriptor`。
6. 将每几个`cell`组成一个`block`(例如`3*3个cell/block`)，一个`block`内所有`cell`的特征`descriptor`串联起来便得到该`block`的`HOG`特征`descriptor`。
7. 将图像`image`内的所有`block`的`HOG`特征`descriptor`串联起来就可以得到该`image`(你要检测的目标)的`HOG`特征`descriptor`了。这个就是最终的可供分类使用的特征向量了。

<img src="./HOG特征/3.png" width=50%>

&emsp;&emsp;具体每一步的详细过程如下：
&emsp;&emsp;(1) 标准化`gamma`空间和颜色空间
&emsp;&emsp;为了减少光照因素的影响，首先需要将整个图像进行规范化(归一化)。在图像的纹理强度中，局部的表层曝光贡献的比重较大，所以这种压缩处理能够有效地降低图像局部的阴影和光照变化。因为颜色信息作用不大，通常先转化为灰度图。`Gamma`压缩公式如下(可以取`Gamma = 1/2`)：

$$
I(x, y) = I(x, y)^{gamma}
$$

&emsp;&emsp;(2) 计算图像梯度
&emsp;&emsp;计算图像横坐标和纵坐标方向的梯度，并据此计算每个像素位置的梯度方向值。求导操作不仅能够捕获轮廓、人影和一些纹理信息，还能进一步弱化光照的影响。图像中像素点$(x, y)$的梯度为：

$$ Gx(x, y) = H(x + 1, y) - H(x - 1, y) $$
$$ Gy(x, y) = H(x, y + 1) - H(x, y - 1) $$

其中$Gx(x, y)$、$Gy(x, y)$和$H(x, y)$分别表示输入图像中像素点$(x, y)$处的水平方向梯度、垂直方向梯度和像素值。像素点$(x, y)$处的梯度幅值和梯度方向分别是：

$$ G(x, y) = \sqrt{G_x(x, y)^2 + G_y(x, y)^2}           $$
$$ \alpha(x, y) = tan^{-1}(\frac{G_y(x, y)}{G_x(x, y)}) $$

&emsp;&emsp;最常用的方法是：首先用$[-1, 0, 1]$梯度算子对原图像做卷积运算，得到$x$方向(水平方向，以向右为正方向)的梯度分量`gradscalx`，然后用$[1, 0, -1]^T$梯度算子对原图像做卷积运算，得到$y$方向(竖直方向，以向上为正方向)的梯度分量`gradscaly`。然后再用以上公式计算该像素点的梯度大小和方向。
&emsp;&emsp;(3) 为每个细胞单元构建梯度方向直方图
&emsp;&emsp;第三步的目的是为局部图像区域提供一个编码，同时能够保持对图像中人体对象的姿势和外观的弱敏感性。
&emsp;&emsp;我们将图像分成若干个单元格`cell`，例如每个`cell`为`6*6`个像素。假设我们采用`9`个`bin`的直方图来统计这`6*6`个像素的梯度信息，也就是将`cell`的梯度方向`360`度分成`9`个方向块，如图所示。例如，如果这个像素的梯度方向是`20`至`40`度之间，直方图第`2`个`bin`的计数就加`1`，于是对`cell`内每个像素用梯度方向在直方图中进行加权投影(映射到固定的角度范围)，就可以得到这个`cell`的梯度方向直方图了，就是该`cell`对应的`9`维特征向量(因为有`9`个`bin`)。

<img src="./HOG特征/4.png" width=60%>

&emsp;&emsp;像素梯度方向用到了，那么梯度大小呢？梯度大小就是作为投影的权值的。例如，这个像素的梯度方向是`20`至`40`度之间，然后它的梯度大小是`2`(假设的值)，那么直方图第`2`个`bin`的计数就不是加`1`了，而是加`2`。
&emsp;&emsp;细胞单元可以是矩形的(`rectangular`)，也可以是星形的(`radial`)。
&emsp;&emsp;(4) 把细胞单元组合成大的块(`block`)，块内归一化梯度直方图
&emsp;&emsp;由于局部光照的变化以及前景-背景对比度的变化，使得梯度强度的变化范围非常大，这就需要对梯度强度做归一化。归一化能够进一步地对光照、阴影和边缘进行压缩。
&emsp;&emsp;作者采取的办法是：把各个细胞单元组合成大的、空间上连通的区间(`blocks`)。这样，一个`block`内所有`cell`的特征向量串联起来便得到该`block`的`HOG`特征。这些区间是互有重叠的，这就意味着每一个单元格的特征会以不同的结果多次出现在最后的特征向量中。我们将归一化之后的块描述符(向量)就称之为`HOG`描述符。

<img src="./HOG特征/5.png">

&emsp;&emsp;区间有两个主要的几何形状：矩形区间(`R-HOG`)和环形区间(`C-HOG`)。`R-HOG`区间大体上是一些方形的格子，它可以有三个参数来表征：每个区间中细胞单元的数目、每个细胞单元中像素点的数目、每个细胞的直方图通道数目。例如，行人检测的最佳参数设置是`3*3`细胞/区间、`6*6`像素/细胞、`9`个直方图通道，则一块的特征数为`3 * 3 * 9`。
&emsp;&emsp;(5) 收集`HOG`特征
&emsp;&emsp;最后一步就是将检测窗口中所有重叠的块进行`HOG`特征的收集，并将它们结合成最终的特征向量供分类使用。

---

&emsp;&emsp;`HOG`特征用于行人检测：

``` python
import cv2

def main():
    img = cv2.imread("hog_input.jpg")  # 入力画像の読み込み
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # グレースケール変換

    # HoG特徴量 + SVMで人の識別器を作成
    hog = cv2.HOGDescriptor()
    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
    hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05}

    human, r = hog.detectMultiScale(gray, **hogParams)  # 作成した識別器で人を検出

    for (x, y, w, h) in human:  # 人の領域を赤色の矩形で囲む
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 200), 3)

    cv2.imshow("result", img)  # 結果を出力
    cv2.waitKey(0)
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
```

<img src="./HOG特征/6.png">